[{"authors":["admin"],"categories":null,"content":"I am currently a Postdoctoral Fellow in SunLab at Georgia Institute of Technology work with Professor Jimeng Sun . Before that, I obtained my Ph.D. degree in School of Electronics Engineering and Computer Sciences at Peking University (PKU) under the supervision of Professor Hongyan Li in 2019, and B.S. degree in School of Science at Beijing University of Posts and Telecommunications (BUPT) in 2014.\nMy research interests are machine learning and data mining for healthcare, especially deep learning methods on Electronic Health Records (EHR) and biomedical signals like Electrocardiogram (ECG) and Electroencephalogram (EEG).\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am currently a Postdoctoral Fellow in SunLab at Georgia Institute of Technology work with Professor Jimeng Sun . Before that, I obtained my Ph.D. degree in School of Electronics Engineering and Computer Sciences at Peking University (PKU) under the supervision of Professor Hongyan Li in 2019, and B.S. degree in School of Science at Beijing University of Posts and Telecommunications (BUPT) in 2014.\nMy research interests are machine learning and data mining for healthcare, especially deep learning methods on Electronic Health Records (EHR) and biomedical signals like Electrocardiogram (ECG) and Electroencephalogram (EEG).","tags":null,"title":"Shenda Hong","type":"authors"},{"authors":null,"categories":null,"content":"","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"b524fbb2219dbb3e7c8e1f3110327fe1","permalink":"/publication/hong2020opportunities/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/publication/hong2020opportunities/","section":"publication","summary":"Objective. To conduct a systematic review of deep learning methods on Electrocardiogram (ECG) data from the perspective of model architecture and their application task. Methods. First, we extensively searched papers deploying deep learning (deep neural network networks) on ECG data that published between January 1st 2010 and September 30th 2019 from Google Scholar, PubMed and DBLP. Then we analyze them in three aspects including task, model and data. Finally, we conclude unresolved challenges and problems that existing models can not handle well. Results. The total number of papers is 124, among them 97 papers are published after in recent two years. Almost all kinds of common deep learning architectures have been used in ECG analytics tasks like disease detection/classification, annotation/localization, sleep staging, biometric human identification, denoising and so on. Conclusion. The number of works about deep learning on ECG data is growing explosively in recent years. Indeed, these works have achieve a far more better performance in terms of accuracy. However, there are some new challenges and problems like interpretability, scalability, efficiency, which need to be addressed and paid more attention. Moreover, it is also worth to investigate by discovering new interesting applications from both the dataset view and the method view. Significance. This paper summarizes existing deep learning methods on modeling ECG data from multiple views, while also point out existing challenges and problems, while can become potential research direction in the future.","tags":null,"title":" Opportunities and Challenges in Deep Learning Methods on Electrocardiogram Data: A Systematic Review ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1587340800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587340800,"objectID":"0728030db139bc374d7e403fa910b5d8","permalink":"/publication/hong2020cardiolearn/","publishdate":"2020-04-20T00:00:00Z","relpermalink":"/publication/hong2020cardiolearn/","section":"publication","summary":"","tags":null,"title":" CardioLearn: A Cloud Deep Learning Service for Cardiac Disease Detection from Electrocardiogram","type":"publication"},{"authors":null,"categories":null,"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"a5afb5b774319758dd03c1369e632434","permalink":"/publication/cao2020cheer/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/publication/cao2020cheer/","section":"publication","summary":"","tags":null,"title":"CHEER: Rich Model Helps Poor Model via Knowledge Infusion","type":"publication"},{"authors":null,"categories":null,"content":"","date":1565827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565827200,"objectID":"8559900dc2a7c4274d4462ef3d5035e3","permalink":"/publication/hong2019mina/","publishdate":"2019-08-15T00:00:00Z","relpermalink":"/publication/hong2019mina/","section":"publication","summary":"Electrocardiography (ECG) signals are commonly used to diagnose various cardiac abnormalities. Recently, deep learning models showed initial success on modeling ECG data, however they are mostly black-box, thus lack interpretability needed for clinical usage. In this work, we propose MultIlevel kNowledge-guided Attention networks (MINA) that predict heart diseases from ECG signals with intuitive explanation aligned with medical knowledge. By extracting multilevel (beat-, rhythm- and frequency-level) domain knowledge features separately, MINA combines the medical knowledge and ECG data via a multilevel attention model, making the learned models highly interpretable. Our experiments showed MINA achieved PR-AUC 0.9436 (outperforming the best baseline by 5.51%) in real world ECG dataset. Finally, MINA also demonstrated robust performance and strong interpretability against signal distortion and noise contamination.","tags":null,"title":" MINA: Multilevel Knowledge-Guided Attention for Modeling Electrocardiography Signals ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1565395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565395200,"objectID":"fa189f42654322d52ff0df4451e38a3c","permalink":"/publication/hong2019rdpd/","publishdate":"2019-08-10T00:00:00Z","relpermalink":"/publication/hong2019rdpd/","section":"publication","summary":"In many situations, we need to build and deploy separate models in related environments with different data qualities. For example, an environment with strong observation equipments (e.g., intensive care units) often provides high-quality multi-modal data, which are acquired from multiple sensory devices and have rich-feature representations. On the other hand, an environment with poor observation equipment (e.g., at home) only provides low-quality, uni-modal data with poor-feature representations. To deploy a competitive model in a poor-data environment without requiring direct access to multi-modal data acquired from a rich-data environment, this paper develops and presents a knowledge distillation (KD) method (RDPD) to enhance a predictive model trained on poor data using knowledge distilled from a high-complexity model trained on rich, private data. We evaluated RDPD on three real-world datasets and shown that its distilled model consistently outperformed all baselines across all datasets, especially achieving the greatest performance improvement over a model trained only on low-quality data by 24.56% on PR-AUC and 12.21% on ROC-AUC, and over that of a state-of-the-art KD model by 5.91% on PR-AUC and 4.44% on ROC-AUC.","tags":null,"title":" RDPD: Rich Data Helps Poor Data via Imitation ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1564963200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564963200,"objectID":"74af3dbdd1f0d540c3c5e1a71328c326","permalink":"/publication/zhou2019kmargin/","publishdate":"2019-08-05T00:00:00Z","relpermalink":"/publication/zhou2019kmargin/","section":"publication","summary":"Atrial Fibrillation (AF) is an abnormal heart rhythm which can trigger cardiac arrest and sudden death. Nevertheless, its interpretation is mostly done by medical experts due to high error rates of computerized interpretation. One study found that only about 66% of AF were correctly recognized from noisy ECGs. This is in part due to insufficient training data, class skewness, as well as semantical ambiguities caused by noisy segments in an ECG record. In this paper, we propose a K-margin-based Residual-Convolution-Recurrent neural network (K-margin-based RCR-net) for AF detection from noisy ECGs. In detail, a skewness-driven dynamic augmentation method is employed to handle the problems of data inadequacy and class imbalance. A novel RCR-net is proposed to automatically extract both long-term rhythm-level and local heartbeat-level characters. Finally, we present a K-margin-based diagnosis model to automatically focus on the most important parts of an ECG record and handle noise by naturally exploiting expected consistency among the segments associated for each record. The experimental results demonstrate that the proposed method with 0.8125 F1NAOP score outperforms all state-of-the-art deep learning methods for AF detection task by 6.8%.","tags":null,"title":" K-margin-based Residual-convolution-recurrent Neural Network for Atrial Fibrillation Detection ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1559606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559606400,"objectID":"3f9a6f7503d9b29a62a0c155072c1440","permalink":"/publication/hong2019combining/","publishdate":"2019-06-04T00:00:00Z","relpermalink":"/publication/hong2019combining/","section":"publication","summary":"Objective. We aim to combine deep neural networks and engineered features (hand-crafted features based on medical domain knowledge) for cardiac arrhythmia detection from short single-lead ECG recordings. Approach. We propose a two-stage method named ENCASE for cardiac arrhythmia detection. The first stage is feature extraction and the second stage is classifier building. In the feature extraction stage, we extract both deep features and engineered features. Deep features are obtained by modifying deep neural networks into a deep feature extractor. Engineered features are extracted by summarizing existing approaches into four feature groups. Then, we propose a feature aggregation approach to combine these features. In the classifier building stage, we build multiple gradient boosting decision trees and combine them to get the final detector. Main results. Experiments are performed on the PhysioNet/Computing in Cardiology Challenge 2017 dataset. Using F 1 scores reported on the hidden test set as measurements, ENCASE got 0.9117 on Normal (F1_N), 0.8128 on Atrial Fibrillation (AF) (F1_A), 0.7505 on Others (F1_O), and 0.5671 on Noise (F1_P). It placed 5th in the Challenge and 8th in the follow-up challenge (ranked by considering the average of Normal, AF, and Others (F1_NAO = 0.825)). When rounding to two decimal places, we were part a three-way tie for 1st place and were part a seven-way tie for 2nd place in the follow-up challenge. Further experiments show that combined features perform better than individual features, and deep features show more importance scores than other features. Significance. ENCASE can benefit from both feature engineering-based methods and recent deep neural networks. It is flexible and can easily assimilate the ability of new cardiac arrhythmia detection methods.","tags":null,"title":" Combining Deep Neural Networks and Engineered Features for Cardiac Arrhythmia Detection from ECG Recordings ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1542240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542240000,"objectID":"c402bc8b9ea51c8232a4e715d43ad33a","permalink":"/publication/shang2018knowledge/","publishdate":"2018-11-15T00:00:00Z","relpermalink":"/publication/shang2018knowledge/","section":"publication","summary":"Predicting medicines for patients with co-morbidity has long been recognized as a hard task due to complex dependencies between diseases and medicines. Efforts have been made recently to build high-order dependency between diseases and medicines by extracting knowledge from electronic health records (EHR). But current works failed to utilize additional knowledge and ignored the data skewness problem which lead to sub-optimal combination of medicines. In this paper, we formulate the medicines prediction task in multi-instance multi-label learning framework considering the multi-diagnoses as input instances and multi-medicines as output labels. We propose a knowledge-guided multi-instance multi-label networks called \\mname where two types of additional knowledge are incorporated into a RNN encoder-decoder model. The utilization of structural knowledge like clinical ontology provides a way to learn better representation called tree embedding by utilizing the ancestors’ information. Contextual knowledge is a global summarization of input instances which is informative for personal prediction. Experiments are conducted on a real world clinical dataset which showed the necessity to combine both contextual and structural knowledge and the \\mname performs better than baselines up to 4+% in terms of Jaccard similarity score.","tags":null,"title":" Knowledge Guided Multi-instance Multi-label Learning via Neural Networks in Medicines Prediction ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1501113600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501113600,"objectID":"90817d4bcebc245fe82f43f01eb9e47c","permalink":"/publication/zhang2017finding/","publishdate":"2017-07-27T00:00:00Z","relpermalink":"/publication/zhang2017finding/","section":"publication","summary":"“Black hole” are widely spread in the mobile communication data, which will highly downgrade the mobile service quality. OLAP tools are extensively used for the decision-support application in the multidimensional data model, which just like the mobile communication case. As different dimensions of the mobile data are incomparable and, thus, can hardly generate one unique final value that satisfies all dimensions. We exploit the skyline operator as the postoperation while building data cubes, named as data cube of skyline. As the skyline of a cuboid is not derivable from another cuboid and the skyline operation is holistic, which makes this problem even challeging. In this paper, we propose a method in materializing the cube of skyline in the big communication data and proof its effectiveness and efficiency by extensive experiments.","tags":null,"title":" Finding the Typical Communication Black Hole in Big Data Environment ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1501113600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501113600,"objectID":"48d4b81b8622002e6521d51a536c04a2","permalink":"/publication/zhang2017rebuild/","publishdate":"2017-07-27T00:00:00Z","relpermalink":"/publication/zhang2017rebuild/","section":"publication","summary":"Inferring users’ social role on a mobile communication network is of significance for various applications, such as financial fraud detection, viral marketing, and target promotions. Different with the social network, which has lots of user generated contents (UGC) including texts, pictures, and videos, considering the privacy issues, mobile communication network only contains the communication pattern data, such as message frequency and phone call frequency as well as duration. Moreover, the profile data of mobile users is always noisy, ambiguous, and sparse, which makes the task more challenging. In this paper, we use the graph embedding methods as a feature extractor and then combine it with the hand-crafted structure-related features in a feed-forward neural network. Different with previous embedding methods, we consider the label info while sampling the context. To handle the noisy and sparsity …","tags":null,"title":" REBUILD: Graph Embedding Based Method for User Social Role Identity on Mobile Communication Network ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1499385600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499385600,"objectID":"a1f5958bd01f0caba1ab3bec14eb3e10","permalink":"/publication/hong2017event/","publishdate":"2017-07-07T00:00:00Z","relpermalink":"/publication/hong2017event/","section":"publication","summary":"Sequential data containing series of events with timestamps is commonly used to record status of things in all aspects of life, and is referred to as temporal event sequences. Learning vector representations is a fundamental task of temporal event sequence mining as it is inevitable for further analysis. Temporal event sequences differ from symbol sequences and numerical time series in that each entry is along with a corresponding time stamp and that the entries are usually sparse in time. Therefore, methods either on symbolic sequences such as word2vec, or on numerical time series such as pattern discovery perform unsatisfactorily. In this paper, we propose an algorithm called event2vec that solves these problems. We first present Event Connection Graph to summarize events while taking time into consideration. Then, we conducts a training Sample Generator to get clean and endless data. Finally, we …","tags":null,"title":" Event2vec: Learning representations of events on temporal sequences ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1495497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1495497600,"objectID":"16c419506e9e1fdc6c7c8fe2d0956538","permalink":"/publication/hong2017assess/","publishdate":"2017-05-23T00:00:00Z","relpermalink":"/publication/hong2017assess/","section":"publication","summary":"Cardiovascular disease (CVD) is the leading cause of death around the world. Researches on assessing patients death risk from Electrocardiographic (ECG) data has attracted increasing attention recently. In this paper, we summarize long-term overwhelming ECG data using morphological concern of overall evolution. And then assessing patients death risk from high value density ECG summarization instead of raw data. Our method is totally unsupervised without the help of expert knowledge. Moreover, it can assist in clinical practice without any additional burden like buy new devices or add more caregivers. Comprehensive results show effectiveness of our method.","tags":null,"title":" Assessing death risk of patients with cardiovascular disease from long-term electrocardiogram streams summarization ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"36ff66ffe4d99d7e8d5f411c2222696b","permalink":"/publication/hong2017encase/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/hong2017encase/","section":"publication","summary":"We propose ENCASE to combine expert features and DNNs (Deep Neural Networks) together for ECG classification. We first explore and implement expert features from statistical area, signal processing area and medical area. Then, we build DNNs to automatically extract deep features. Besides, we propose a new algorithm to find the most representative wave (called centerwave) among long ECG record, and extract features from centerwave. Finally, we combine these features together and put them into ensemble classifiers. Experiment on 4-class ECG data classification reports 0.84 F1 score, which is much better than any of the single model.","tags":null,"title":" ENCASE: an ENsemble ClASsifiEr for ECG Classification Using Expert Features and Deep Neural Networks","type":"publication"},{"authors":null,"categories":null,"content":"","date":1474588800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1474588800,"objectID":"86bc89d70d30d2bacd35fe7e07a8e9d9","permalink":"/publication/lin2016fvbm/","publishdate":"2016-09-23T00:00:00Z","relpermalink":"/publication/lin2016fvbm/","section":"publication","summary":"Closeness centrality is often used to identify the top-k most prominent nodes in a network. Real networks, however, are rapidly evolving all the time, which results in the previous methods hard to adapt. A more scalable method that can immediately react to the dynamic network is demanding. In this paper, we endeavour to propose a filter and verification framework to handle such new trends in the large-scale network. We adopt several pruning methods to generate a much smaller candidate set so that bring down the number of necessary time-consuming calculations. Then we do verification on the subset; which is a much time efficient manner. To further speed up the filter procedure, we incremental update the influenced part of the data structure. Extensive experiments using real networks demonstrate its high scalability and efficiency.","tags":null,"title":" FVBM: A Filter-Verification-Based Method for Finding Top-k Closeness Centrality on Dynamic Social Networks ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1474588800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1474588800,"objectID":"182500e243533d43f87a9fb57fd66e30","permalink":"/publication/wu2016real/","publishdate":"2016-09-23T00:00:00Z","relpermalink":"/publication/wu2016real/","section":"publication","summary":"Anomaly detection is a popular research in the age of Big Data. As a typical application scenario, anomaly detection over ECG data stream is confronted with particular difficulties including high real-time requirement and poor data quality. In this article, a novel method based on component spectrum is presented to provide a practicable solution for the problem. Experiments on real data show that the proposed method achieves high sensitivity, high specificity and low false alarm rate.","tags":null,"title":" Real-time anomaly detection over ECG data stream based on component spectrum ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1459209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1459209600,"objectID":"f010b22fc56bd0a7c63a8fc261b523fb","permalink":"/publication/qiu2016novel/","publishdate":"2016-03-29T00:00:00Z","relpermalink":"/publication/qiu2016novel/","section":"publication","summary":"In intensive care units (ICU), electrocardiogram (ECG) waveforms show diverse variationsunder different patients' physical conditions. In general, physicians can diagnose patients efficientlyby detecting any disorder of heart rate or rhythm and any change in the morphological pattern of ECG data, which contain underlying semantics. To help physicians better analyze ECG data in a fairly short time, it is essential to develop a novel method for mining semantics from ECG patterns. This paper is the very first time to characterize ECG patterns by using Prefix Scalable Pattern Tree (PSP-Tree). Comparing with similar currently existing methods, PSP-Tree can mine significant semantics, such as scalability, temporality and hierarchy over ECG patterns. We conduct extensive experiments on real ECG data set which are obtained from PhysioBank Community and Beijing No. 3 People Hospital. The experiment results show that our method performs more feasibly and effectively than other related work.","tags":null,"title":" A novel method for mining semantics from patterns over ecg data ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1459209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1459209600,"objectID":"758ef21e3997c0c1e4a127ba9594ef0f","permalink":"/publication/hong2016combining/","publishdate":"2016-03-29T00:00:00Z","relpermalink":"/publication/hong2016combining/","section":"publication","summary":"Multiple concurrent physiological streams generated by various medical devices play important roles in patient condition assessment. However, these physiological streams needto be analyzed together and output in real-time for preciseand timely controlling and management, which poses a non-trivial challenge to existing methods. This paper presents ourresearch on real-time assessing based on this kind of data. To address this problem, we first extract sketches from original data with the help of adaptive sampling and wave splittingalgorithm, then define scalable operators on sketches and propose MUNCA (MUlti-dimensional Nearest Center Analysis) to combine these multiple concurrent data together for anal-ysis. Experiments on real data demonstrate the effectiveness and efficiency of the proposed method.","tags":null,"title":" Combining Multiple Concurrent Physiological Streams to Assessing Patients Condition ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1418947200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1418947200,"objectID":"a538e5d8bd1836bdbbe64e7c5e1d40e3","permalink":"/publication/yin2014segment/","publishdate":"2014-12-19T00:00:00Z","relpermalink":"/publication/yin2014segment/","section":"publication","summary":"In many applications, the data in time series appears highly periodic, but never exactly repeats itself. Such series are called pseudo periodic time series. The prediction of pseudo periodic time series is an important and non-trivial problem. Since the period interval is not fixed and unpredictable, errors will accumulate when traditional periodic methods are employed. Meanwhile, many time series contain a vast number of abnormal variations. These variations can neither be simply filtered out nor predicted by its neighboring points. Given that no specific method is available for pseudo periodic time series as of yet, the paper proposes a segment-wise method for the prediction of pseudo periodic time series with abnormal variations. Time series are segmented by the variation patterns of each period in the method. Only the segment corresponding to the target time series is chosen for prediction, which leads to …","tags":null,"title":" A Segment-Wise Method for Pseudo Periodic Time Series Prediction ","type":"publication"},{"authors":null,"categories":null,"content":"","date":1402876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1402876800,"objectID":"c8d9e874fc9d55a1036d0a3295acec70","permalink":"/publication/qiu2014finding/","publishdate":"2014-06-16T00:00:00Z","relpermalink":"/publication/qiu2014finding/","section":"publication","summary":"In modern cities, more and more vehicles, such as taxis, have been equipped with GPS devices for localization and navigation. The GPS-equipped taxis can be viewed as pervasive sensors and the large scale traces allow us to reveal many hidden “facts” about the city dynamics. In this paper, we aim to estimate the wait time and probability of taking a vacant taxi according to time and position. Further more, we provide recommendations for passengers who want to take a vacant taxi. To achieve these objectives, firstly we preprocess the large scale taxi GPS traces data set to generate the Map Grid Based(MGB) index. Secondly, with the MGB index, we apply the nonhomogeneous Poisson process corrected by the conditions of road and weather(NPPCRW) method to perform estimation and recommendation. We build our system based on a large scale real-world GPS traces data set generated from more …","tags":null,"title":" Finding vacant taxis using large scale GPS traces ","type":"publication"}]